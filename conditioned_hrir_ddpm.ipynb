{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:54:33.930744Z",
     "start_time": "2023-11-27T14:54:29.288279100Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torchaudio.transforms as TT\n",
    "import librosa\n",
    "import os\n",
    "import logging\n",
    "import tqdm as tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Assuming you have labeled_data.csv in the same directory as your script\n",
    "#csv_file_path = 'labeled_data.csv'\n",
    "data_directory = '/nas/home/jalbarracin/datasets/hrir_st'\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for filename in os.listdir(data_directory):\n",
    "    # Extract subject ID and measurement point from the file name\n",
    "    parts = os.path.splitext(filename)[0].split('_')\n",
    "    subject_id = int(parts[0][2:])  # Extract subject ID, assuming it starts with \"pp\"\n",
    "    measurement_point = int(parts[-1])  # Extract measurement point\n",
    "\n",
    "    # Load audio data\n",
    "    file_path = os.path.join(data_directory, filename)\n",
    "    wave, sr = torchaudio.load(file_path, normalize=True)\n",
    "\n",
    "    # Append the audio data, subject ID, and measurement point to the dataset\n",
    "    dataset.append({'audio': wave, 'subject_id': subject_id, 'measurement_point': measurement_point})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:54:46.278593100Z",
     "start_time": "2023-11-27T14:54:43.888453300Z"
    }
   },
   "id": "ce50a604c5e0ed39"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 3096\n",
      "Sample channels and length: torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "element = dataset[0]\n",
    "audio_ex = element['audio']\n",
    "print(f\"Sample channels and length: {audio_ex.shape}\")\n",
    "for item in dataset:\n",
    "    audio_data = item['audio']\n",
    "    subject_id = item['subject_id']\n",
    "    measurement_point = item['measurement_point']\n",
    "    #print(subject_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:54:52.143356200Z",
     "start_time": "2023-11-27T14:54:52.123431200Z"
    }
   },
   "id": "1bae6eaade863bc7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function for the DataLoader. Assumes each element in batch is a dictionary with 'audio' and 'measurement_point' keys.\n",
    "    \"\"\"\n",
    "    audio_batch = [item['audio'] for item in batch]\n",
    "    measurement_point_batch = [item['measurement_point'] for item in batch]\n",
    "    return {'audio': torch.stack(audio_batch), 'measurement_point': torch.tensor(measurement_point_batch)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:54:56.078640200Z",
     "start_time": "2023-11-27T14:54:56.078640200Z"
    }
   },
   "id": "5bce76cb4e4ae2fa"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1  # len(dataset) // 4\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:54:58.488165800Z",
     "start_time": "2023-11-27T14:54:58.478666700Z"
    }
   },
   "id": "701bc06bf05743d"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params:  18570466\n"
     ]
    },
    {
     "data": {
      "text/plain": "SimpleUnet_cond(\n  (time_mlp): Sequential(\n    (0): SinusoidalPositionEmbeddings()\n    (1): Linear(in_features=32, out_features=32, bias=True)\n    (2): ReLU()\n  )\n  (conv0): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (downs): ModuleList(\n    (0): Block(\n      (time_mlp): Linear(in_features=32, out_features=128, bias=True)\n      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (transform): Conv1d(128, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (1): Block(\n      (time_mlp): Linear(in_features=32, out_features=256, bias=True)\n      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n      (transform): Conv1d(256, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bnorm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bnorm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (2): Block(\n      (time_mlp): Linear(in_features=32, out_features=512, bias=True)\n      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (transform): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (3): Block(\n      (time_mlp): Linear(in_features=32, out_features=1024, bias=True)\n      (conv1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n      (transform): Conv1d(1024, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n      (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bnorm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bnorm2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n  )\n  (ups): ModuleList(\n    (0): Block(\n      (time_mlp): Linear(in_features=32, out_features=512, bias=True)\n      (conv1): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (transform): ConvTranspose1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (1): Block(\n      (time_mlp): Linear(in_features=32, out_features=256, bias=True)\n      (conv1): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n      (transform): ConvTranspose1d(256, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bnorm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bnorm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (2): Block(\n      (time_mlp): Linear(in_features=32, out_features=128, bias=True)\n      (conv1): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (transform): ConvTranspose1d(128, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (3): Block(\n      (time_mlp): Linear(in_features=32, out_features=64, bias=True)\n      (conv1): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n      (transform): ConvTranspose1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n  )\n  (output): Conv1d(64, 2, kernel_size=(1,), stride=(1,))\n  (label_emb): Embedding(36, 32)\n)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_ch)\n",
    "        if up:\n",
    "            self.conv1 = nn.Conv1d(2 * in_ch, out_ch, kernel_size=3, padding=1)\n",
    "            self.transform = nn.ConvTranspose1d(out_ch, out_ch, kernel_size=4, stride=2, padding=1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "            self.transform = nn.Conv1d(out_ch, out_ch, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.bnorm1 = nn.BatchNorm1d(out_ch)\n",
    "        self.bnorm2 = nn.BatchNorm1d(out_ch)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Remove the last singleton dimension\n",
    "        #print(\"x before\", x.shape)\n",
    "        x = x.squeeze(2)\n",
    "        #print(\"x shape\",x.shape)\n",
    "        # First Conv\n",
    "        h = self.bnorm1(self.relu(self.conv1(x)))  # Adjust here\n",
    "        #print(\"After conv1 shape:\", h.shape)\n",
    "        # Time embedding\n",
    "        time_emb = self.relu(self.time_mlp(t))\n",
    "        # Extend last dimension\n",
    "        time_emb = time_emb.unsqueeze(-1)\n",
    "        # Add time channel\n",
    "        h = h + time_emb\n",
    "        # Second Conv\n",
    "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
    "        #print(\"After conv2 shape:\", h.shape)\n",
    "        # Down or Upsample\n",
    "        return self.transform(h)\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        # TODO: Double check the ordering here\n",
    "        return embeddings\n",
    "\n",
    "class SimpleUnet_cond(nn.Module):\n",
    "    def __init__(self, num_classes=None):\n",
    "        super().__init__()\n",
    "        audio_channels = 2  # Adjust for stereo audio\n",
    "        down_channels = (64, 128, 256, 512, 1024)\n",
    "        up_channels = (1024, 512, 256, 128, 64)\n",
    "        out_dim = 2  # Adjust for stereo audio\n",
    "        time_emb_dim = 32\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Initial projection\n",
    "        self.conv0 = nn.Conv1d(audio_channels, down_channels[0], kernel_size=3, padding=1)  # Adjust here\n",
    "\n",
    "        # Downsample\n",
    "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i + 1], time_emb_dim) \\\n",
    "                                    for i in range(len(down_channels) - 1)])\n",
    "        # Upsample\n",
    "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i + 1], time_emb_dim, up=True) \\\n",
    "                                  for i in range(len(up_channels) - 1)])\n",
    "\n",
    "        # Output layer\n",
    "        self.output = nn.Conv1d(up_channels[-1], out_dim, kernel_size=1)\n",
    "        \n",
    "        if num_classes is not None:\n",
    "            self.label_emb = nn.Embedding(num_classes,time_emb_dim)\n",
    "\n",
    "    def forward(self, x, timestep, y):\n",
    "        # Embed time\n",
    "        t = self.time_mlp(timestep)\n",
    "        print(\"Time embedding shape:\", t.shape)\n",
    "        if y is not None:\n",
    "            t +=self.label_emb(y)\n",
    "        # Initial conv\n",
    "        x = x.squeeze(0)\n",
    "        print(\"before conv0 shape:\", x.shape)\n",
    "        x = self.conv0(x) \n",
    "        print(\"After conv0 shape:\", x.shape)\n",
    "        # Unet\n",
    "        residual_inputs = []\n",
    "        for i, down in enumerate(self.downs):\n",
    "            #print(\"hola\")\n",
    "            x = down(x, t)\n",
    "            #print(f\"After downsampling block {i} shape:\", x.shape)\n",
    "            residual_inputs.append(x)\n",
    "        for i, up in enumerate(self.ups):\n",
    "            residual_x = residual_inputs.pop()\n",
    "            # Add residual x as additional channels\n",
    "            x = torch.cat((x, residual_x), dim=1)\n",
    "            x = up(x, t)\n",
    "            #print(f\"After upsampling block {i} shape:\", x.shape)\n",
    "        # Assuming the final output layer is 1D\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "model = SimpleUnet_cond(num_classes=36)\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T16:00:19.824388300Z",
     "start_time": "2023-11-27T16:00:19.698027300Z"
    }
   },
   "id": "ca0c710be28c71b0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.step = 0\n",
    "\n",
    "    def update_model_average(self, ma_model, current_model):\n",
    "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "            old_weight, up_weight = ma_params.data, current_params.data\n",
    "            ma_params.data = self.update_average(old_weight, up_weight)\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "    def step_ema(self, ema_model, model, step_start_ema=2000):\n",
    "        if self.step < step_start_ema:\n",
    "            self.reset_parameters(ema_model, model)\n",
    "            self.step += 1\n",
    "            return\n",
    "        self.update_model_average(ema_model, model)\n",
    "        self.step += 1\n",
    "\n",
    "    def reset_parameters(self, ema_model, model):\n",
    "        ema_model.load_state_dict(model.state_dict())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:55:19.053222200Z",
     "start_time": "2023-11-27T14:55:19.053222200Z"
    }
   },
   "id": "1141726fe549568d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, audio_length=256, device=\"cuda\"):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "\n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "        self.audio_length = audio_length\n",
    "        self.device = device\n",
    "\n",
    "    def prepare_noise_schedule(self):\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "\n",
    "    def noise_images(self, x, t):\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        Ɛ = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n",
    "\n",
    "    def sample_timesteps(self, n):\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "\n",
    "    def sample(self, model, n, labels, cfg_scale=3):\n",
    "        logging.info(f\"Sampling {n} new audio....\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n, 2, 256)).to(self.device)\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "                t = (torch.ones(n) * i).long().to(self.device)\n",
    "                predicted_noise = model(x, t, labels)\n",
    "                if cfg_scale > 0:\n",
    "                    uncond_predicted_noise = model(x, t, None)\n",
    "                    predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        #x = (x.clamp(-1, 1) + 1) / 2\n",
    "        #x = (x * 255).type(torch.uint8)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:55:22.558294700Z",
     "start_time": "2023-11-27T14:55:22.548543Z"
    }
   },
   "id": "ca943818be5b33a6"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "def train(epochs,dataloader):\n",
    "    #setup_logging(args.run_name)\n",
    "    #device = args.device\n",
    "    #dataloader = get_data(args)\n",
    "    model = SimpleUnet_cond(num_classes=36).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "    #mse = nn.MSELoss()\n",
    "    diffusion = Diffusion(device=device)\n",
    "    #logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n",
    "    l = len(dataloader)\n",
    "    ema = EMA(0.995)\n",
    "    ema_model = copy.deepcopy(model).eval().requires_grad_(False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        logging.info(f\"Starting epoch {epoch}:\")\n",
    "        #pbar = tqdm(dataloader)\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            audio = batch['audio'].to(device)\n",
    "            labels = batch['measurement_point'].to(device)\n",
    "            t = diffusion.sample_timesteps(audio.shape[0]).to(device)\n",
    "            x_t, noise = diffusion.noise_images(audio, t)\n",
    "            if np.random.random() < 0.1:\n",
    "                labels = None\n",
    "            predicted_noise = model(x_t, t, labels)\n",
    "            loss = F.l1_loss(noise, predicted_noise)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ema.step_ema(ema_model, model)\n",
    "\n",
    "            #pbar.set_postfix(L1_Loss=loss.item())\n",
    "            #logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            labels = torch.arange(10).long().to(device)\n",
    "            sampled_images = diffusion.sample(model, n=len(labels), labels=labels)\n",
    "            ema_sampled_images = diffusion.sample(ema_model, n=len(labels), labels=labels)\n",
    "            #plot_images(sampled_images)\n",
    "            #save_images(sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}.jpg\"))\n",
    "            #save_images(ema_sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}_ema.jpg\"))\n",
    "            #torch.save(model.state_dict(), os.path.join(\"models\", args.run_name, f\"ckpt.pt\"))\n",
    "            #torch.save(ema_model.state_dict(), os.path.join(\"models\", args.run_name, f\"ema_ckpt.pt\"))\n",
    "            #torch.save(optimizer.state_dict(), os.path.join(\"models\", args.run_name, f\"optim.pt\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T16:01:45.907233600Z",
     "start_time": "2023-11-27T16:01:45.907233600Z"
    }
   },
   "id": "e2551b975b95068e"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time embedding shape: torch.Size([1, 32])\n",
      "before conv0 shape: torch.Size([1, 2, 256])\n",
      "After conv0 shape: torch.Size([1, 64, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:251: UserWarning: Error detected in ReluBackward0. Traceback of forward call that caused the error:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n",
      "    app.start()\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 737, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n",
      "    await result\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_936353/14863123.py\", line 1, in <module>\n",
      "    train(epochs=100, dataloader=dataloader)\n",
      "  File \"/tmp/ipykernel_936353/49164459.py\", line 28, in train\n",
      "    predicted_noise = model(x_t, t, labels)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_936353/1324902820.py\", line 85, in forward\n",
      "    t = self.time_mlp(timestep)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 101, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "  File \"/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/nn/functional.py\", line 1471, in relu\n",
      "    result = torch.relu(input)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1, 32]], which is output 0 of ReluBackward0, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[32], line 32\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epochs, dataloader)\u001B[0m\n\u001B[1;32m     29\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39ml1_loss(noise, predicted_noise)\n\u001B[1;32m     31\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 32\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     34\u001B[0m ema\u001B[38;5;241m.\u001B[39mstep_ema(ema_model, model)\n",
      "File \u001B[0;32m/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/nas/home/jalbarracin/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1, 32]], which is output 0 of ReluBackward0, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "train(epochs=100, dataloader=dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T16:01:50.763383500Z",
     "start_time": "2023-11-27T16:01:50.377038600Z"
    }
   },
   "id": "c60a1686a2139395"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
